      
# =============================================================================
# PRIVATEER Anomaly Detection - Environment Configuration
# =============================================================================
# This file is used to configure the application without modifying the source code.
# Uncomment and change the values as needed.

# -------------------------------------
# MLFlow Configuration
# -------------------------------------
# The address of your MLFlow tracking server. This is critical.
PRIVATEER_MLFLOW_SERVER_IP=0.0.0.0
PRIVATEER_MLFLOW_SERVER_PORT=5001
PRIVATEER_MLFLOW_TRACKING_URI=http://${PRIVATEER_MLFLOW_SERVER_IP}:${PRIVATEER_MLFLOW_SERVER_PORT}
PRIVATEER_MLFLOW_EXPERIMENT_NAME=privateer-ad
# Path on the host machine to store MLflow artifacts (e.g., models)
PRIVATEER_MLFLOW_ARTIFACT_PATH=./mlflow_logs/mlruns
# Path on the host machine to store the MLflow database
PRIVATEER_MLFLOW_DB_PATH=./mlflow_logs/database
# -------------------------------------
# Data Processing Configuration
# -------------------------------------
# The sequence length for the time series model.
PRIVATEER_DATA_SEQ_LEN=12
# Batch size for training and evaluation. Adjust based on your GPU memory.
PRIVATEER_DATA_BATCH_SIZE=4096
# Number of workers for data loading. Adjust based on your CPU cores.
PRIVATEER_DATA_NUM_WORKERS=16

# -------------------------------------
# Model Architecture Configuration
# -------------------------------------
# Name of the model in the MLflow registry.
PRIVATEER_MODEL_MODEL_NAME=TransformerAD
PRIVATEER_MODEL_NUM_LAYERS=1
PRIVATEER_MODEL_EMBED_DIM=32
PRIVATEER_MODEL_LATENT_DIM=16
PRIVATEER_MODEL_NUM_HEADS=1
PRIVATEER_MODEL_DROPOUT=0.2

# -------------------------------------
# Training Configuration
# -------------------------------------
PRIVATEER_TRAIN_EPOCHS=100
PRIVATEER_TRAIN_LEARNING_RATE=0.0001
# The metric used to select the "champion" model.
PRIVATEER_TRAIN_TARGET_METRIC=val_f1-score
# The optimization direction for the target metric.
PRIVATEER_TRAIN_DIRECTION=maximize
# Early stopping settings
PRIVATEER_TRAIN_ES_ENABLED=True
PRIVATEER_TRAIN_ES_PATIENCE=20
PRIVATEER_TRAIN_ES_WARMUP=10

# -------------------------------------
# Differential Privacy (DP) Configuration
# -------------------------------------
# Set to 'False' to train a non-DP model.
PRIVATEER_DP_DP_ENABLED=True
# The privacy budget epsilon. Smaller is more private.
PRIVATEER_DP_TARGET_EPSILON=0.3
# The privacy budget delta. Should be smaller than 1/num_samples.
PRIVATEER_DP_TARGET_DELTA=1e-7
# Gradient clipping norm for Opacus.
PRIVATEER_DP_MAX_GRAD_NORM=0.5
# Use Opacus secure mode.
PRIVATEER_DP_SECURE_MODE=False

# -------------------------------------
# Autotuning (Optuna) Configuration
# -------------------------------------
PRIVATEER_AUTOTUNE_STUDY_NAME=privateer-autotune
PRIVATEER_AUTOTUNE_N_TRIALS=30
# The database for storing Optuna trial results. Can be changed to a remote DB.
PRIVATEER_AUTOTUNE_STORAGE_URL=sqlite:///optuna_study.db

# -------------------------------------
# Federated Learning (FL) Configuration
# -------------------------------------
# Address the FL server listens on.
PRIVATEER_FL_SERVER_ADDRESS=[::]:8081
PRIVATEER_FL_NUM_ROUNDS=100
# Number of clients to sample for each round.
PRIVATEER_FL_FRACTION_FIT=1.0
PRIVATEER_FL_FRACTION_EVALUATE=1.0
# Set to 'False' to disable secure aggregation.
PRIVATEER_FL_SECURE_AGGREGATION_ENABLED=True
# Number of local epochs each client trains per round.
PRIVATEER_FL_EPOCHS_PER_ROUND=1