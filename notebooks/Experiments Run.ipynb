{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "import itertools\n",
    "import uuid\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "\n",
    "from dataloader.dataloader import *\n",
    "from training.training import *\n",
    "from models.rae import *\n",
    "from utils.utils import *\n",
    "from visualizations.visualizations import *\n",
    "from evaluation.evaluation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"CUDA is available. Training on GPU.\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"CUDA is not available. Training on CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"../Data/Data v5\"\n",
    "\n",
    "\n",
    "# df = pd.read_csv(os.path.join(data_folder, \"amari_ue_data_final_v5_no_outliers.csv\"))\n",
    "# df = df.sort_values([\"imeisv\", \"_time\"], ascending = True)\n",
    "# dataset_used = 'no_outliers'\n",
    "\n",
    "df = pd.read_csv(os.path.join(data_folder, \"amari_ue_data_final_v5_no_outliers_scaled.csv\"))\n",
    "df = df.sort_values([\"imeisv\", \"_time\"], ascending = True)\n",
    "dataset_used = 'no_outliers_scaled'\n",
    "\n",
    "# df = pd.read_csv(os.path.join(data_folder, \"amari_ue_data_final_v5_no_outliers_scaled_sep.csv\"))\n",
    "# df = df.sort_values([\"imeisv\", \"_time\"], ascending = True)\n",
    "# dataset_used = 'no_outliers_scaled_sep'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_columns = [\n",
    "#     'dl_bitrate','ul_bitrate', \n",
    "#     'cell_x_dl_retx', 'cell_x_dl_tx',\n",
    "#     'cell_x_ul_retx', 'cell_x_ul_tx',\n",
    "#     'ul_total_bytes_non_incr', 'dl_total_bytes_non_incr'\n",
    "# ]\n",
    "\n",
    "# feature_columns = [\n",
    "#     'dl_bitrate','ul_bitrate','ul_total_bytes_non_incr', 'dl_total_bytes_non_incr'\n",
    "# ]\n",
    "\n",
    "feature_columns = [\n",
    "    'ul_bitrate'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_avg_label = False # True for applying rolling avg\n",
    "\n",
    "if rolling_avg_label:\n",
    "    df[feature_columns] = df[feature_columns].rolling(window=360).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benign_data_starting_point = \"2024-03-20 14:14:50.19\"\n",
    "benign_data_ending_point = \"2024-03-23 16:26:19.00\"\n",
    "\n",
    "\n",
    "filter_1 = (df['_time'].between(benign_data_starting_point, benign_data_ending_point))\n",
    "filter_2 = (~df['imeisv'].isin(['8642840401594200', '8642840401612300','8642840401624200','3557821101183501']))\n",
    "\n",
    "df.drop(df[filter_1 & filter_2].index, inplace = True)\n",
    "benign_data = df[df['label'] == 0].copy()\n",
    "benign_data = benign_data.sort_values(['imeisv','_time'])\n",
    "print(benign_data.shape[0])\n",
    "malicious_data = df[df['label'] == 1].copy()\n",
    "malicious_data = malicious_data.sort_values(['imeisv','_time'])\n",
    "print(malicious_data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space_dict = {\n",
    "    'window_size': [60, 90, 120], \n",
    "    'batch_size' : [32],\n",
    "    'model_arch_config': [\n",
    "        {\n",
    "        'hidden_dim1' : 25, \n",
    "        'hidden_dim2' : 50, \n",
    "        },\n",
    "        {\n",
    "        'hidden_dim1' : 50, \n",
    "        'hidden_dim2' : 100, \n",
    "        },\n",
    "        {\n",
    "        'hidden_dim1' : 25, \n",
    "        'hidden_dim2' : 25, \n",
    "        },\n",
    "        {\n",
    "        'hidden_dim1' : 50, \n",
    "        'hidden_dim2' : 50, \n",
    "        }\n",
    "    ],\n",
    "    'dropout':[0.2, 0.3],\n",
    "    'layer_norm_flag':[True, False],\n",
    "    'loss_function' : [nn.L1Loss, nn.MSELoss], \n",
    "    'lr' : [1e-4, 1e-3],\n",
    "    'num_epochs':[52]\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for window_size, batch_size in itertools.product(search_space_dict['window_size'], search_space_dict['batch_size']):\n",
    "    for config in search_space_dict['model_arch_config']:\n",
    "        hidden_dim1 = config['hidden_dim1']\n",
    "        hidden_dim2 = config['hidden_dim2']\n",
    "        for dropout, layer_norm_flag, loss_function, lr, num_epochs in itertools.product(\n",
    "            search_space_dict['dropout'], search_space_dict['layer_norm_flag'],\n",
    "            search_space_dict['loss_function'], search_space_dict['lr'],\n",
    "            search_space_dict['num_epochs']):\n",
    "            \n",
    "            experiment_id = str(uuid.uuid4())\n",
    "            \n",
    "            parameters = {\n",
    "                'window_size': window_size,\n",
    "                'step_size': int(window_size/3),\n",
    "                'batch_size': batch_size,\n",
    "                'hidden_dim1': hidden_dim1,\n",
    "                'hidden_dim2': hidden_dim2,\n",
    "                'dropout': dropout,\n",
    "                'layer_norm_flag': layer_norm_flag,\n",
    "                'loss_function': loss_function,\n",
    "                'lr': lr,\n",
    "                'num_epochs': num_epochs\n",
    "            }\n",
    "            \n",
    "            print(\"##########################################################\")\n",
    "            print_parameters(parameters, experiment_id)\n",
    "            \n",
    "            train_data_loader, val_data_loader, mal_data_loader = create_ds_loader(\n",
    "                benign_data, \n",
    "                malicious_data, \n",
    "                parameters['window_size'], \n",
    "                parameters['step_size'], \n",
    "                feature_columns, \n",
    "                parameters['batch_size']\n",
    "            )\n",
    "            \n",
    "            rae_model = LSTMAutoencoder(\n",
    "                input_dim = len(feature_columns), \n",
    "                hidden_dim1 = hidden_dim1, \n",
    "                hidden_dim2 = hidden_dim2, \n",
    "                output_dim = len(feature_columns), \n",
    "                dropout = dropout, \n",
    "                layer_norm_flag = layer_norm_flag\n",
    "            )\n",
    "\n",
    "            rae_model.to(device)\n",
    "\n",
    "            early_stopping = EarlyStopping(patience=7, min_delta=0.)\n",
    "            criterion = loss_function()\n",
    "            \n",
    "            history = rae_model.train_model(\n",
    "                num_epochs = parameters['num_epochs'], \n",
    "                early_stopping = early_stopping, \n",
    "                train_data_loader = train_data_loader, \n",
    "                val_data_loader = val_data_loader, \n",
    "                mal_data_loader = mal_data_loader, \n",
    "                device = device, \n",
    "                criterion = criterion,  \n",
    "                lr = lr\n",
    "            )\n",
    "            \n",
    "            parameters['loss_function'] = parameters['loss_function'].__name__\n",
    "            \n",
    "            additional_metadata = {\n",
    "                \"rolling_avg\": rolling_avg_label,\n",
    "                \"feature_columns\": feature_columns,\n",
    "                'dataset_used': dataset_used\n",
    "            }\n",
    "            \n",
    "            \n",
    "            save_experiment_results(history, parameters, additional_metadata, experiment_id, results_dir='../results')\n",
    "            \n",
    "            del rae_model\n",
    "            torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "privateer_venv",
   "language": "python",
   "name": "privateer_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
