{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import functools\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "\n",
    "from dataloader.dataloader import *\n",
    "from training.training import *\n",
    "from models.rae import *\n",
    "from utils.utils import *\n",
    "from visualizations.visualizations import *\n",
    "from evaluation.evaluation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"CUDA is available. Training on GPU.\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"CUDA is not available. Training on CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"../Data/Data v5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"../Data/Data v5\"\n",
    "df = pd.read_csv(os.path.join(data_folder, \"amari_ue_data_final_v5_smoothed_scaled.csv\"))\n",
    "df = df.sort_values([\"imeisv\", \"_time\"], ascending = True)\n",
    "df['imeisv'] = df['imeisv'].astype(str)\n",
    "dataset_used = 'smoothed_scaled'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benign_data_starting_point = \"2024-03-20 14:14:50.19\"\n",
    "benign_data_ending_point = \"2024-03-23 16:26:19.00\"\n",
    "\n",
    "\n",
    "benign_filter_1 = (df['_time'].between(benign_data_starting_point, benign_data_ending_point))\n",
    "benign_filter_2 = (~df['imeisv'].isin(['8642840401594200', '8642840401612300','8642840401624200','3557821101183501']))\n",
    "benign_filter_3 = (df['label'] == 0)\n",
    "benign_data_filter = (benign_filter_1 & benign_filter_2 & benign_filter_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# benign data\n",
    "benign_data_train = df[benign_data_filter].copy()\n",
    "benign_data_train = benign_data_train.sort_values(['imeisv','_time'])\n",
    "print(benign_data_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benign_data_test_period_start = \"2024-03-24 01:20:00.19\"\n",
    "benign_devices_for_testing = ['8609960468879057', '8628490433231157','8677660403123800']\n",
    "\n",
    "benign_filter_4 = (df['_time'] >= benign_data_test_period_start)\n",
    "benign_filter_5 = (df['imeisv'].isin(benign_devices_for_testing))\n",
    "benign_data_filter_test = (benign_filter_3 & benign_filter_4 & benign_filter_5)\n",
    "\n",
    "benign_data_test = df[benign_data_filter_test].copy()\n",
    "benign_data_test = benign_data_test.sort_values(['imeisv','_time'])\n",
    "print(benign_data_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#malicious data\n",
    "attck_1_start = \"2024-03-23 21:26:00\"\n",
    "attck_1_end = \"2024-03-23 22:23:00\"\n",
    "ues_to_exclude_in_1st_attck = [\n",
    "    '8628490433231157','8609960480666910',\n",
    "    '3557821101183501'] #'8677660403123800' '8642840401594200'\n",
    "\n",
    "attck_2_start = \"2024-03-23 22:56:00\"\n",
    "attck_2_end = \"2024-03-23 23:56:00\"\n",
    "ues_to_exclude_in_2nd_attck = [\n",
    "    '8609960480666910','8642840401612300'\n",
    "]\n",
    "\n",
    "mal_filter_1 = (\n",
    "    df['_time'].between(attck_1_start, attck_1_end)\n",
    "    & (~df['imeisv'].isin(ues_to_exclude_in_1st_attck))\n",
    ")\n",
    "\n",
    "mal_filter_2 = (\n",
    "    df['_time'].between(attck_2_start, attck_2_end)\n",
    "    & (~df['imeisv'].isin(ues_to_exclude_in_2nd_attck))\n",
    ")\n",
    "\n",
    "mal_filter_3 = (df['label'] == 1)\n",
    "\n",
    "malicious_data = df[(mal_filter_1 | mal_filter_2) & mal_filter_3].copy()\n",
    "malicious_data = malicious_data.sort_values(['imeisv','_time'])\n",
    "print(malicious_data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"../results/experiments_metadata.json\")\n",
    "exp_metadata = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_df = {}\n",
    "for exp_id, exp_info in exp_metadata.items():\n",
    "    parameters = exp_info['parameters']\n",
    "    flattened_info = {\n",
    "        **parameters,\n",
    "        'epochs_trained':exp_info['epochs_trained'], \n",
    "        'results_file': exp_info['results_file'], \n",
    "        'timestamp': exp_info['timestamp'],\n",
    "        'min_train_loss': exp_info['min_train_loss'],\n",
    "        'min_val_loss': exp_info['min_val_loss'],\n",
    "        'min_train_val_gap': exp_info['min_train_val_gap'],\n",
    "        'features': exp_info['feature_columns'],\n",
    "        'rolling_avg': exp_info['rolling_avg'],\n",
    "        'dataset_used': exp_info['dataset_used']\n",
    "        }\n",
    "    data_for_df[exp_id] = flattened_info\n",
    "\n",
    "exp_df = pd.DataFrame.from_dict(data_for_df, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_df.sort_values('min_train_val_gap', ascending = True).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_parameters = exp_metadata['5bfa52f8-e8c6-4899-963d-3ebd80be60f9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_hist = load_history_from_pickle('../results/5bfa52f8-e8c6-4899-963d-3ebd80be60f9_history.pkl', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot training validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_train_val_loss(exp_hist.train_losses, exp_hist.val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot rec loss as scatterplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch_size = 1\n",
    "benign_test_data_loader, mal_test_data_loader = create_test_ds_loaders(\n",
    "    benign_data_test, \n",
    "    malicious_data, \n",
    "    120, \n",
    "    30, \n",
    "    features = exp_parameters['feature_columns'], \n",
    "    batch_size = test_batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rae_model = LSTMAutoencoder(\n",
    "    input_dim = len(exp_parameters['feature_columns']), \n",
    "    hidden_dim1 = exp_parameters['parameters']['hidden_dim1'], \n",
    "    hidden_dim2 = exp_parameters['parameters']['hidden_dim2'], \n",
    "    output_dim = len(exp_parameters['feature_columns']), \n",
    "    dropout = exp_parameters['parameters']['dropout'], \n",
    "    layer_norm_flag = exp_parameters['parameters']['layer_norm_flag']\n",
    ")\n",
    "\n",
    "rae_model.load_state_dict(exp_hist.model_weights)\n",
    "rae_model.to(device)\n",
    "\n",
    "criterion = nn.L1Loss() if exp_parameters['parameters']['loss_function'] == 'L1Loss' else nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benign_test_losses, mal_test_losses = evaluate(rae_model, criterion, benign_test_data_loader, mal_test_data_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scatter_plot_rec_loss(benign_test_losses, mal_test_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Roc Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds, roc_auc, optimal_threshold = calculate_threshold(benign_test_losses, mal_test_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curve(fpr, tpr, thresholds , roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threshold selection & Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy, precision, recall, f1, tp_rate, tn_rate, fp_rate, fn_rate = infer(benign_test_losses, mal_test_losses, optimal_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original vs reconstructed TS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imeisv = \"8628490433231157\"\n",
    "\n",
    "imeisv_series = df[\n",
    "        (df['imeisv'] == imeisv)\n",
    "    ].sort_values('_time', ascending = True)[exp_parameters['feature_columns']]\n",
    "\n",
    "window_length = exp_parameters['parameters']['window_size'] \n",
    "\n",
    "split_arrays = []\n",
    "\n",
    "for start in range(0, len(imeisv_series) - window_length + 1, window_length):\n",
    "    end = start + window_length\n",
    "    split_arrays.append(imeisv_series[start:end].values)\n",
    "\n",
    "rae_model.to(device)\n",
    "rae_model.eval()\n",
    "\n",
    "imeisv_original = []\n",
    "imeisv_rec = []\n",
    "with torch.no_grad(): \n",
    "    for ar in split_arrays:\n",
    "        ar_tensor = torch.from_numpy(ar).to(device).float()\n",
    "        imeisv_rec.append(rae_model(ar_tensor).to('cpu').numpy())\n",
    "        imeisv_original.append(ar_tensor.to('cpu').numpy())\n",
    "\n",
    "imeisv_original = functools.reduce(lambda a, b: np.concatenate([a,b]), imeisv_original).flatten()\n",
    "imeisv_rec = functools.reduce(lambda a, b: np.concatenate([a,b]), imeisv_rec).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric in exp_parameters['feature_columns']:\n",
    "    plot_original_vs_rec(imeisv_original, imeisv_rec, imeisv, metric)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "privateer_venv",
   "language": "python",
   "name": "privateer_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
